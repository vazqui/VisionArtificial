{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce313c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage import feature\n",
    "from skimage import exposure\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import category_encoders as ce\n",
    "from sklearn import naive_bayes\n",
    "import pandas as pd\n",
    "from sklearn import metrics \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.base import clone\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b28862",
   "metadata": {},
   "source": [
    "### Variables y funciones programadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b36b3e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ivana\\Desktop\\Universidad\\4º curso\\1º semestre\\Vision artificial\\Practicas\\Practica final\\VisionArtificial\n"
     ]
    }
   ],
   "source": [
    "#Parametros de raiz\n",
    "raiz=os.getcwd()\n",
    "print(raiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b10661fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tamaño de ventana para homogeneizar las imagenes\n",
    "tamanoVentana = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9856c73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratarImagenes(directorio, X_Train, Y_Train, X_Test, Y_Test,num):\n",
    "    os.chdir(raiz+directorio)\n",
    "    aux = os.listdir()\n",
    "    cont = len(aux) * 0.8\n",
    "    k = 0\n",
    "    for j in aux:\n",
    "        img = cv2.imread(j)\n",
    "\n",
    "        # Convertimos a escala de grises\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #Aplicamos el filtro de la mediana que es el mejor para eliminar el ruido sal y pimienta\n",
    "        img = cv2.medianBlur(img,5)\n",
    "        \n",
    "        #Aplicamos el filtro gaussiano para eliminar posibles ruidos restantes\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "        #Redimensionamos las imagenes para tener en todas el mismo tamaño\n",
    "        imagen_ampliada = cv2.resize(img, (tamanoVentana,tamanoVentana))\n",
    "        \n",
    "        # Detectamos los bordes con Canny\n",
    "        canny = cv2.Canny(imagen_ampliada, 50, 150)\n",
    "        \n",
    " \n",
    "        # Buscamos los contornos\n",
    "        (contornos,_) = cv2.findContours(canny.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    " \n",
    "        cv2.drawContours(imagen_ampliada,contornos,-1,(0,0,255), 2)\n",
    "        \n",
    "        if(k<cont):\n",
    "            X_Train.append(imagen_ampliada)\n",
    "            Y_Train.append(num)  \n",
    "        else:\n",
    "            X_Test.append(imagen_ampliada)\n",
    "            Y_Test.append(num)  \n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5114c663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parametros para el HOG\n",
    "pixels_per_cell=(8,8)\n",
    "cells_per_block=(2,2)\n",
    "orientations = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c4cd28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOG(images, pixels_per_cell, cells_per_block):\n",
    "    lista_hog=[]\n",
    "    lista_img_hog=[]\n",
    "    for i,img in enumerate(images):\n",
    "        carac,img_hog=hog(img, orientations=9, pixels_per_cell=pixels_per_cell, cells_per_block=cells_per_block,visualize=True, multichannel=False)\n",
    "        lista_hog.append(carac)\n",
    "        lista_img_hog.append(img_hog)\n",
    "    return np.copy(lista_hog),lista_img_hog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33976875",
   "metadata": {},
   "source": [
    "# Fase 1: Entrenamiento de un clasificador de monedas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e06216",
   "metadata": {},
   "source": [
    "## Fase 1.1: Análisis del conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf28a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cargamos la imagen y la procesamos para eliminar el ruido\n",
    "X_Train = []\n",
    "Y_Train = []\n",
    "X_Test = []\n",
    "Y_Test = []\n",
    "\n",
    "tratarImagenes('\\\\train\\\\1c',X_Train, Y_Train, X_Test, Y_Test,1)\n",
    "tratarImagenes('\\\\train\\\\1e',X_Train, Y_Train, X_Test, Y_Test,2)\n",
    "tratarImagenes('\\\\train\\\\2c',X_Train, Y_Train, X_Test, Y_Test,4)\n",
    "tratarImagenes('\\\\train\\\\2e',X_Train, Y_Train, X_Test, Y_Test,5)\n",
    "tratarImagenes('\\\\train\\\\5c',X_Train, Y_Train, X_Test, Y_Test,7)\n",
    "tratarImagenes('\\\\train\\\\10c',X_Train, Y_Train, X_Test, Y_Test,0)\n",
    "tratarImagenes('\\\\train\\\\20c',X_Train, Y_Train, X_Test, Y_Test,3)\n",
    "tratarImagenes('\\\\train\\\\50c',X_Train, Y_Train, X_Test, Y_Test,6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29e9b791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de train\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1041"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tamaño de train\") \n",
    "len(X_Train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "183ee61a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Tamaño de test\") \n",
    "len(X_Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f5c55903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#comprobando si se ha aplicado bien el filtro y la redimension\n",
    "\n",
    "cv2.imshow(\"imagen\",X_Train[456])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "cv2.imshow(\"imagen2\",X_Test[100])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b258cbed",
   "metadata": {},
   "source": [
    "## Fase 1.2: HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c239fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_Train_Coin,_ = HOG(X_Train, pixels_per_cell,cells_per_block)\n",
    "Y_Train_Coin = np.copy(Y_Train)\n",
    "\n",
    "X_Test_Coin,_ = HOG(X_Test,pixels_per_cell,cells_per_block)\n",
    "Y_Test_Coin = np.copy(Y_Test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038d4372",
   "metadata": {},
   "source": [
    "# Fase 1.3 Entrenamiento\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6e79d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [SVC(), LogisticRegression(random_state=0, max_iter=1000), GaussianNB(), DecisionTreeClassifier()]\n",
    "\n",
    "clf_names = ['SVM', 'Regr Logistica', 'NB Gaussiano', 'Decision Tree']\n",
    "\n",
    "score_list = []\n",
    "aux_params = []\n",
    "best_score = np.NINF\n",
    "\n",
    "parameters_dict = {'SVM':{'kernel':('linear','rbf'), 'C':[1,10],'gamma':[0.1,0.001]},\n",
    "                    'Regr Logistica':{'C':[0.01,1,10,1000] },\n",
    "                    'NB Gaussiano':{'var_smoothing': np.logspace(0, -9,num=10)},\n",
    "                    'Decision Tree':{'min_samples_split':[2,3,4], 'criterion':['gini','entropy']},\n",
    "                 }\n",
    "\n",
    "for i,(clf_aux,clf_name) in enumerate(zip(classifiers,clf_names)):\n",
    "        clf = clone(clf_aux)\n",
    "        clf = GridSearchCV(clf,parameters_dict[clf_name], cv=2, n_jobs=-1)\n",
    "        clf.fit(X_Train_Coin,Y_Train_Coin)\n",
    "        \n",
    "        score=round(clf.score(X_Test_Coin,Y_Test_Coin)*100,2)\n",
    "        score_list.append(score)\n",
    "        aux_params.append(clf.best_params_)\n",
    "        if score >= best_score:\n",
    "            best_score = score\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40e6cdc",
   "metadata": {},
   "source": [
    "### Mejores parámetros para cada clasificador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b10beb",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4b06474f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para SVM\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'linear'}\n",
      "Porcentaje de train: \n",
      "0.9356388088376562\n",
      "Porcentaje de test: \n",
      "0.65625\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros para SVM\") \n",
    "print(aux_params[0])\n",
    "\n",
    "svc = svm.SVC(kernel='rbf',C=10,gamma=0.001,max_iter=1000)\n",
    "svc.fit(X_Train_Coin,Y_Train_Coin)\n",
    "acc = svc.score(X_Train_Coin,Y_Train_Coin)\n",
    "print(\"Porcentaje de train: \")\n",
    "print(acc)\n",
    "\n",
    "Y_Test_Coin = np.asarray(Y_Test)\n",
    "acc = svc.score(X_Test_Coin,Y_Test_Coin)\n",
    "print(\"Porcentaje de test: \")\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672d107f",
   "metadata": {},
   "source": [
    "### Regresion logística"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0c848d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para regresion logística\n",
      "{'C': 1}\n",
      "Porcentaje de train: \n",
      "1.0\n",
      "Porcentaje de test: \n",
      "0.63671875\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros para regresion logística\") \n",
    "print(aux_params[1])\n",
    "\n",
    "logistic_regression = LogisticRegression(C=1,max_iter=1000)\n",
    "logistic_regression.fit(X_Train_Coin,Y_Train_Coin)\n",
    "\n",
    "accRegLog = logistic_regression.score(X_Train_Coin,Y_Train_Coin)\n",
    "print(\"Porcentaje de train: \")\n",
    "print(accRegLog)\n",
    "\n",
    "\n",
    "Y_Test_Coin = np.asarray(Y_Test)\n",
    "accRegLogTest = logistic_regression.score(X_Test_Coin,Y_Test_Coin)\n",
    "print(\"Porcentaje de test: \")\n",
    "print(accRegLogTest)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08449b5e",
   "metadata": {},
   "source": [
    "### NB Gaussiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f678365c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para NB Gaussiano\n",
      "{'var_smoothing': 0.01}\n",
      "Porcentaje de train: \n",
      "0.6628242074927954\n",
      "Porcentaje de test: \n",
      "0.4921875\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros para NB Gaussiano\") \n",
    "print(aux_params[2])\n",
    "\n",
    "nb = naive_bayes.GaussianNB(var_smoothing = 0.1)\n",
    "nb.fit(X_Train_Coin,Y_Train_Coin)\n",
    "nbscore = nb.score(X_Train_Coin,Y_Train_Coin)\n",
    "print(\"Porcentaje de train: \")\n",
    "print(nbscore)\n",
    "\n",
    "Y_Test_Coin = np.asarray(Y_Test)\n",
    "nbscore_test = nb.score(X_Test_Coin,Y_Test_Coin)\n",
    "print(\"Porcentaje de test: \")\n",
    "print(nbscore_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09aaee3",
   "metadata": {},
   "source": [
    "### Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06248249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros para Decision tree\n",
      "{'criterion': 'entropy', 'min_samples_split': 4}\n",
      "Porcentaje de train: \n",
      "0.9731027857829011\n",
      "Porcentaje de test: \n",
      "0.63671875\n"
     ]
    }
   ],
   "source": [
    "print(\"Mejores parámetros para Decision tree\") \n",
    "print(aux_params[3])\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(criterion='gini',min_samples_split=3)\n",
    "decision_tree.fit(X_Train_Coin,Y_Train_Coin)\n",
    "accDecTree = decision_tree.score(X_Train_Coin,Y_Train_Coin)\n",
    "print(\"Porcentaje de train: \")\n",
    "print(accDecTree)\n",
    "\n",
    "Y_Test_Coin = np.asarray(Y_Test)\n",
    "decision_tree_test = logistic_regression.score(X_Test_Coin,Y_Test_Coin)\n",
    "print(\"Porcentaje de test: \")\n",
    "print(decision_tree_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4671ee1d",
   "metadata": {},
   "source": [
    "# Código de generación de csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "699f39d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tratarImagenes2(directorio, X_Train):\n",
    "    os.chdir(raiz+directorio)\n",
    "    aux = os.listdir()\n",
    "    for j in aux:\n",
    "        img = cv2.imread(j)\n",
    "\n",
    "        # Convertimos a escala de grises\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        #Aplicamos el filtro de la mediana que es el mejor para eliminar el ruido sal y pimienta\n",
    "        img = cv2.medianBlur(img,5)\n",
    "        \n",
    "        #Aplicamos el filtro gaussiano para eliminar posibles ruidos restantes\n",
    "        img = cv2.GaussianBlur(img,(5,5),0)\n",
    "\n",
    "        #Redimensionamos las imagenes para tener en todas el mismo tamaño\n",
    "        imagen_ampliada = cv2.resize(img, (tamanoVentana,tamanoVentana))\n",
    "        \n",
    "        X_Train.append(imagen_ampliada)\n",
    "        \n",
    "\n",
    "X_public_test = []\n",
    "\n",
    "tratarImagenes2('\\\\public_test',X_public_test)\n",
    "\n",
    "X_public_test_Coin,_ = HOG(X_public_test, pixels_per_cell,cells_per_block)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c76e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = svm.SVC(kernel='rbf',C=10,gamma=0.001,max_iter=1000)\n",
    "svc.fit(X_public_test_Coin,Y_Train_Coin)\n",
    "acc = svc.score(X_public_test_Coin,Y_Train_Coin)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffcef6b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y_Train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14520/452579419.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# writing the data rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_Train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[0mcsvwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_Train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_Train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y_Train' is not defined"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "fields = [\"Id\", \"Expected\"] \n",
    "filename = \"results.csv\"\n",
    "\n",
    "# writing to csv file \n",
    "with open(filename, 'w', newline=\"\") as csvfile: \n",
    "    # creating a csv writer object \n",
    "    csvwriter = csv.writer(csvfile, delimiter=',') \n",
    "\n",
    "    # writing the fields \n",
    "    csvwriter.writerow(fields) \n",
    "\n",
    "    # writing the data rows \n",
    "    for i in range(len(test_labels)):\n",
    "        csvwriter.writerow([test_image_ids[i], test_labels[i]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py38ml] *",
   "language": "python",
   "name": "conda-env-py38ml-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
